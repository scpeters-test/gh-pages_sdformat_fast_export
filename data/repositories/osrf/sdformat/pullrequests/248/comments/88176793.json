{"links": {"self": {"href": "data/repositories/osrf/sdformat/pullrequests/248/comments/88176793.json"}, "html": {"href": "#!/osrf/sdformat/pull-requests/248/_/diff#comment-88176793"}}, "parent": {"id": 88173498, "links": {"self": {"href": "data/repositories/osrf/sdformat/pullrequests/248/comments/88173498.json"}, "html": {"href": "#!/osrf/sdformat/pull-requests/248/_/diff#comment-88173498"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 248, "links": {"self": {"href": "data/repositories/osrf/sdformat/pullrequests/248.json"}, "html": {"href": "#!/osrf/sdformat/pull-requests/248"}}, "title": "Added camera intrinsics (fx, fy, cx, cy, s)."}, "content": {"raw": "Good night :slight_smile: \n\nYou are correct. I made a mistake in the default parameters when computing the focal length from the camera resolution \\(I forgot to divide the resolution in half\\).\n\nFor a camera with 60\u00ba HFOV and 320x240 the focal length should be 277 pixels.\n\nFor future reference:\n\nfocal\\_length\\_in\\_pixels = \\(image\\_width\\_in\\_pixels \\* 0.5\\) / tan\\(field\\_of\\_view\\_in\\_degrees \\* 0.5 \\* PI/180\\)  \n  \nI have been using the code in this PR for augmented reality purposes for modeling a projector as a camera \\(using Gazebo as a flexible rendering engine\\) and it has experimentally work with good accuracy \\(between 1 and 3 pixels of projection error when the projector is on a overhead position over a workstation at around 1.8 m\\).  \nHere is an example:  \n[https://www.youtube.com/watch?v=b51MOa9KWZ8](https://www.youtube.com/watch?v=b51MOa9KWZ8)  \n  \nI have inspected the math formulation presented in:  \n[http://ksimek.github.io/2013/06/03/calibrated\\_cameras\\_in\\_opengl](http://ksimek.github.io/2013/06/03/calibrated_cameras_in_opengl)  \n[http://ksimek.github.io/2013/08/13/intrinsic](http://ksimek.github.io/2013/08/13/intrinsic)  \nAnd other sources and it seems correct.  \n  \nBut as every model is an approximation of reality, there is always room for improvement :slight_smile: \n\nThe advantage of this approach is that it allows good camera / projector modeling with low computational overhead since it can use native functions of gpus and opengl to render the camera image.", "markup": "markdown", "html": "<p>Good night <img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f642.png\" alt=\"\ud83d\ude42\" title=\":slight_smile:\" data-emoji-short-name=\":slight_smile:\" /> </p>\n<p>You are correct. I made a mistake in the default parameters when computing the focal length from the camera resolution (I forgot to divide the resolution in half).</p>\n<p>For a camera with 60\u00ba HFOV and 320x240 the focal length should be 277 pixels.</p>\n<p>For future reference:</p>\n<p>focal_length_in_pixels = (image_width_in_pixels * 0.5) / tan(field_of_view_in_degrees * 0.5 * PI/180)  </p>\n<p>I have been using the code in this PR for augmented reality purposes for modeling a projector as a camera (using Gazebo as a flexible rendering engine) and it has experimentally work with good accuracy (between 1 and 3 pixels of projection error when the projector is on a overhead position over a workstation at around 1.8 m).<br />\nHere is an example:<br />\n<a data-is-external-link=\"true\" href=\"https://www.youtube.com/watch?v=b51MOa9KWZ8\" rel=\"nofollow\">https://www.youtube.com/watch?v=b51MOa9KWZ8</a>  </p>\n<p>I have inspected the math formulation presented in:<br />\n<a data-is-external-link=\"true\" href=\"http://ksimek.github.io/2013/06/03/calibrated_cameras_in_opengl\" rel=\"nofollow\">http://ksimek.github.io/2013/06/03/calibrated_cameras_in_opengl</a><br />\n<a data-is-external-link=\"true\" href=\"http://ksimek.github.io/2013/08/13/intrinsic\" rel=\"nofollow\">http://ksimek.github.io/2013/08/13/intrinsic</a><br />\nAnd other sources and it seems correct.  </p>\n<p>But as every model is an approximation of reality, there is always room for improvement <img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f642.png\" alt=\"\ud83d\ude42\" title=\":slight_smile:\" data-emoji-short-name=\":slight_smile:\" /> </p>\n<p>The advantage of this approach is that it allows good camera / projector modeling with low computational overhead since it can use native functions of gpus and opengl to render the camera image.</p>", "type": "rendered"}, "created_on": "2019-01-16T00:08:43.264203+00:00", "user": {"display_name": "Carlos Miguel Correia da Costa", "uuid": "{8f4eaa49-0391-4770-bde5-edb5358b51a8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B8f4eaa49-0391-4770-bde5-edb5358b51a8%7D"}, "html": {"href": "https://bitbucket.org/%7B8f4eaa49-0391-4770-bde5-edb5358b51a8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/323d40c3bb4988fad287b6879453b67dd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCC-6.png"}}, "nickname": "carlosmccosta", "type": "user", "account_id": "557058:1675d077-a0e4-4cbc-bcf3-3dcc212ee41c"}, "updated_on": "2019-01-16T00:08:43.389898+00:00", "type": "pullrequest_comment", "id": 88176793}